{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "In_class_exercise_09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muraliRoyal1/venkatasiva_INFO5731_Fall2020/blob/master/In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsZmc1G7gik4"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 11/11/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeNSQvnbgik6"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeLTQmyxgik8"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy\n",
        "traindata = pd.read_fwf(\"/content/sample_data/stsa-train.txt\", header = None)\n",
        "testdata = pd.read_fwf(\"/content/sample_data/stsa-test.txt\", header = None)\n",
        "del traindata[2]\n",
        "del testdata[2]\n",
        "del testdata[3]\n",
        "traindata = traindata.rename(columns={0: \"Polarity\", 1: \"Text\"})\n",
        "testdata = testdata.rename(columns={0: \"Polarity\", 1: \"Text\"})\n",
        "x_train, x_validate, y_train, y_validate = sklearn.model_selection.train_test_split(traindata['Text'], traindata['Polarity'], train_size=0.8, test_size=0.2)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO3VBxUv4RmQ"
      },
      "source": [
        "k_f = KFold(n_splits=10)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoRQPjeGgilB",
        "outputId": "ea68ffdd-eefd-42e0-ba60-64b5b7b4eda5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#NaiveBayes\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "for train_index, test_index in k_f.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "pipeline_nb = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "alg = pipeline_nb.fit(x_train_k, y_train_k)\n",
        "test = alg.predict(testdata['Text'])\n",
        "print('accuracy=', accuracy_score(testdata['Polarity'], test))\n",
        "print(' recall =', recall_score(testdata['Polarity'], test))\n",
        "print('precision=', accuracy_score(testdata['Polarity'],test))\n",
        "print('f1-score=', f1_score(testdata['Polarity'],test, average='macro'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy= 0.7984623833058759\n",
            " recall = 0.8712871287128713\n",
            "precision= 0.7984623833058759\n",
            "f1-score= 0.7974299976872767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH-W7q2QgilF",
        "outputId": "02143a29-735f-4733-9f53-05b6c4ae2a19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# SVM\n",
        "from sklearn.svm import LinearSVC\n",
        "for train_index, test_index in k_f.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "pipeline_svm = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', LinearSVC())])\n",
        "alg = pipeline_svm.fit(x_train_k, y_train_k)\n",
        "test = alg.predict(testdata['Text'])\n",
        "print('accuracy=', accuracy_score(testdata['Polarity'], test))\n",
        "print(' recall =', recall_score(testdata['Polarity'], test))\n",
        "print('precision=', accuracy_score(testdata['Polarity'],test))\n",
        "print('f1-score=', f1_score(testdata['Polarity'],test, average='macro'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy= 0.8045030203185063\n",
            " recall = 0.8151815181518152\n",
            "precision= 0.8045030203185063\n",
            "f1-score= 0.8044859808574345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6S_5ndNgilI",
        "outputId": "94da7c4e-1435-4508-bc19-d163302b15b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " #KNN\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "for train_index, test_index in k_f.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "pipeline_knn = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', KNeighborsClassifier())])\n",
        "alg = pipeline_knn.fit(x_train_k, y_train_k)\n",
        "test = alg.predict(testdata['Text'])\n",
        "print('accuracy=', accuracy_score(testdata['Polarity'], test))\n",
        "print(' recall =', recall_score(testdata['Polarity'], test))\n",
        "print('precision=', accuracy_score(testdata['Polarity'],test))\n",
        "print('f1-score=', f1_score(testdata['Polarity'],test, average='macro'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy= 0.7287204832509611\n",
            " recall = 0.7623762376237624\n",
            "precision= 0.7287204832509611\n",
            "f1-score= 0.7284354094718284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xUIo0ZXgilK",
        "outputId": "7b9edc1d-6c2a-452a-9a89-0bcf8abb3a73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Decision Tree\n",
        "\n",
        "from sklearn import tree\n",
        "for train_index, test_index in k_f.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "pipeline_dt = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', tree.DecisionTreeClassifier())])\n",
        "alg = pipeline_dt.fit(x_train_k, y_train_k)\n",
        "test = alg.predict(testdata['Text'])\n",
        "print('accuracy=', accuracy_score(testdata['Polarity'], test))\n",
        "print(' recall =', recall_score(testdata['Polarity'], test))\n",
        "print('precision=', accuracy_score(testdata['Polarity'],test))\n",
        "print('f1-score=', f1_score(testdata['Polarity'],test, average='macro'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy= 0.6161449752883031\n",
            " recall = 0.6336633663366337\n",
            "precision= 0.6161449752883031\n",
            "f1-score= 0.6160407656868894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz_4gBgXgilN",
        "outputId": "c3acf0df-0910-4736-b630-093d75d35954",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "for train_index, test_index in k_f.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "pipeline_rf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', RandomForestClassifier(n_estimators=50))])\n",
        "alg = pipeline_rf.fit(x_train_k, y_train_k)\n",
        "test = alg.predict(testdata['Text'])\n",
        "print('accuracy=', accuracy_score(testdata['Polarity'], test))\n",
        "print(' recall =', recall_score(testdata['Polarity'], test))\n",
        "print('precision=', accuracy_score(testdata['Polarity'],test))\n",
        "print('f1-score=', f1_score(testdata['Polarity'],test, average='macro'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy= 0.7073036792970895\n",
            " recall = 0.7612761276127613\n",
            "precision= 0.7073036792970895\n",
            "f1-score= 0.7064879453856796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DEFQmYRgilP",
        "outputId": "0b3fca61-e2e6-406b-865e-7131adf961e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#  XGBoost\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "for train_index, test_index in k_f.split(x_train, y_train):\n",
        "    x_train_k, y_train_k = x_train[train_index], y_train[train_index]\n",
        "    x_test_k, y_test_k = x_train[test_index], y_train[test_index]\n",
        "pipeline_xg = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', GradientBoostingClassifier(n_estimators=10,verbose=1))])\n",
        "alg= pipeline_xg.fit(x_train_k, y_train_k)\n",
        "test = alg.predict(testdata['Text'])\n",
        "print('accuracy=', accuracy_score(testdata['Polarity'], test))\n",
        "print(' recall =', recall_score(testdata['Polarity'], test))\n",
        "print('precision=', accuracy_score(testdata['Polarity'],test))\n",
        "print('f1-score=', f1_score(testdata['Polarity'],test, average='macro'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.3761            0.37s\n",
            "         2           1.3690            0.32s\n",
            "         3           1.3626            0.26s\n",
            "         4           1.3565            0.22s\n",
            "         5           1.3514            0.18s\n",
            "         6           1.3466            0.15s\n",
            "         7           1.3424            0.11s\n",
            "         8           1.3378            0.07s\n",
            "         9           1.3335            0.04s\n",
            "        10           1.3298            0.00s\n",
            "accuracy= 0.5683690280065898\n",
            " recall = 0.9240924092409241\n",
            "precision= 0.5683690280065898\n",
            "f1-score= 0.5064489299369382\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}