{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "In_Class_exercises_10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muraliRoyal1/venkatasiva_INFO5731_Fall2020/blob/master/In_Class_exercises_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MHr9nW6wnCS"
      },
      "source": [
        "# In class exercise 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrgKF_c6wnCS"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K means, \n",
        "DBSCAN,\n",
        "Hierarchical clustering. \n",
        "\n",
        "You can refer to of the codes from  the follwing link below. \n",
        "https://www.kaggle.com/karthik3890/text-clustering \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x3h8NpywnCS"
      },
      "source": [
        "#importing necessary libraries\n",
        "import pandas as pd\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qPpRlRA02Hx"
      },
      "source": [
        "#load the data\n",
        "mysample=pd.read_csv(\"/content/sample_data/amazon_reviews_1.csv\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "P3SfKKv7q29d",
        "outputId": "9b41666c-dce2-4f54-8096-1995c1d1f063"
      },
      "source": [
        "mysample.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0\" Cell Phones Unlocked Android 5.1 MTK6580 ...</td>\n",
              "      <td>JUNING</td>\n",
              "      <td>89.99</td>\n",
              "      <td>5</td>\n",
              "      <td>This phone works well as how it supposed to be...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0\" Cell Phones Unlocked Android 5.1 MTK6580 ...</td>\n",
              "      <td>JUNING</td>\n",
              "      <td>89.99</td>\n",
              "      <td>5</td>\n",
              "      <td>The phone is an unlocked phone and the suppor...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0\" Cell Phones Unlocked Android 5.1 MTK6580 ...</td>\n",
              "      <td>JUNING</td>\n",
              "      <td>89.99</td>\n",
              "      <td>1</td>\n",
              "      <td>Cheap-- I am sending it back..</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0\" Cell Phones Unlocked Android 5.1 MTK6580 ...</td>\n",
              "      <td>JUNING</td>\n",
              "      <td>89.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I bought this to replace my samsung galaxy s3 ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0\" Cell Phones Unlocked Android 5.1 MTK6580 ...</td>\n",
              "      <td>JUNING</td>\n",
              "      <td>89.99</td>\n",
              "      <td>5</td>\n",
              "      <td>My niece is 15 and so hard on phones, my siste...</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Product Name  ... Review Votes\n",
              "0  5.0\" Cell Phones Unlocked Android 5.1 MTK6580 ...  ...          4.0\n",
              "1  5.0\" Cell Phones Unlocked Android 5.1 MTK6580 ...  ...          1.0\n",
              "2  5.0\" Cell Phones Unlocked Android 5.1 MTK6580 ...  ...          4.0\n",
              "3  5.0\" Cell Phones Unlocked Android 5.1 MTK6580 ...  ...          1.0\n",
              "4  5.0\" Cell Phones Unlocked Android 5.1 MTK6580 ...  ...          4.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdS44g5jOAPO",
        "outputId": "764f19b1-5b35-440e-dc0e-525dda6aef1f"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from textblob import Word\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7695t9kIOGPW"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uepg9Tt-OI2O"
      },
      "source": [
        "import gensim\n",
        "import scipy\n",
        "from scipy.cluster import hierarchy\n",
        "from sklearn.cluster import AgglomerativeClustering"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQtIZIiaveZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19dcf712-15f9-4c1c-fed2-0b198aa09f89"
      },
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "mysample['CleanedReviews'] = mysample['Reviews'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "mysample['CleanedReviews'] = mysample['CleanedReviews'].str.replace('[^\\w\\s]','')\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzO-Y4z0OShW"
      },
      "source": [
        "stop = stopwords.words('english')\n",
        "mysample['CleanedReviews'] = mysample['CleanedReviews'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "mysample['CleanedReviews'] = mysample['CleanedReviews'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slyNVK8_OSuG"
      },
      "source": [
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectors = tfidf_vectorizer.fit_transform(mysample['CleanedReviews'].values)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XABrpGdwtOaG"
      },
      "source": [
        "# Implementing K-MEANS CLUSTERING\n",
        "\n",
        "no_clusters = [x for x in range(3, 10)]\n",
        "squared_errors = []\n",
        "for cluster in no_clusters:\n",
        "    kmeans = KMeans(n_clusters = cluster).fit(tfidf_vectors)\n",
        "    squared_errors.append(kmeans.inertia_)\n",
        "\n",
        "     "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toIJbtQXOgqZ",
        "outputId": "c67a46fe-6f08-46e9-8c54-61bff49e8e9d"
      },
      "source": [
        "optimal_clusters = np.argmin(squared_errors) + 2 \n",
        "xy = (optimal_clusters, min(squared_errors))\n",
        "print (\"Optimal number of clusters: - \", optimal_clusters)\n",
        "print (\"loss for Optimal cluster: - \", min(squared_errors))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal number of clusters: -  8\n",
            "loss for Optimal cluster: -  412.35887679458534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-Ej47-GPFp6",
        "outputId": "a16f044c-a32d-405b-de38-241f3060e71a"
      },
      "source": [
        "optimal_k = 8\n",
        "model = KMeans(n_clusters = optimal_k).fit(tfidf_vectors)\n",
        "labels = model.labels_\n",
        "cluster_centers = model.cluster_centers_\n",
        "terms = tfidf_vectorizer.get_feature_names()\n",
        "silhouette_score = metrics.silhouette_score(tfidf_vectors, labels, metric='euclidean')\n",
        "print('The Silhouette Score is: ', silhouette_score)\n",
        "mysample['TF-IDF Cluster Labels'] = labels\n",
        "print(mysample.groupby(['TF-IDF Cluster Labels'])['Reviews'].count())\n",
        "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "for i in range(optimal_k):\n",
        "    print(\"Cluster %d:\" % i, end='')\n",
        "    for ind in order_centroids[i, :optimal_k]:\n",
        "        print(' %s' % terms[ind], end='')\n",
        "        print()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Silhouette Score is:  0.09740502415252084\n",
            "TF-IDF Cluster Labels\n",
            "0    128\n",
            "1     28\n",
            "2     20\n",
            "3     12\n",
            "4    118\n",
            "5     25\n",
            "6     38\n",
            "7    143\n",
            "Name: Reviews, dtype: int64\n",
            "Cluster 0: excelent\n",
            " working\n",
            " chinese\n",
            " bueno\n",
            " exelente\n",
            " like\n",
            " love\n",
            " item\n",
            "Cluster 1: excellent\n",
            " product\n",
            " recommend\n",
            " thank\n",
            " arrived\n",
            " much\n",
            " condition\n",
            " seller\n",
            "Cluster 2: junk\n",
            " worst\n",
            " bought\n",
            " 60\n",
            " charging\n",
            " pas\n",
            " one\n",
            " even\n",
            "Cluster 3: ok\n",
            " far\n",
            " quite\n",
            " wcdma\n",
            " people\n",
            " slow\n",
            " congratulection\n",
            " entering\n",
            "Cluster 4: phone\n",
            " sim\n",
            " card\n",
            " screen\n",
            " work\n",
            " use\n",
            " review\n",
            " one\n",
            "Cluster 5: excelente\n",
            " telefono\n",
            " muy\n",
            " bueno\n",
            " producto\n",
            " faster\n",
            " favorite\n",
            " favor\n",
            "Cluster 6: good\n",
            " phone\n",
            " product\n",
            " buy\n",
            " mobile\n",
            " thanks\n",
            " waist\n",
            " work\n",
            "Cluster 7: phone\n",
            " work\n",
            " great\n",
            " charge\n",
            " nice\n",
            " arrived\n",
            " waste\n",
            " money\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hSK00pR5Lf0"
      },
      "source": [
        "# DBSCAN CLUSTERING\n",
        "list_of_reviews=[]\n",
        "for review in mysample['CleanedReviews'].values:\n",
        "    list_of_reviews.append(review.split())\n",
        "w2v_model=gensim.models.Word2Vec(list_of_reviews, size=100, workers=4)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_UymPxDPyEM",
        "outputId": "d82eb8db-0a0f-4839-9e23-b10a3bf5fc23"
      },
      "source": [
        "review_vectors = []\n",
        "for review in list_of_reviews:\n",
        "    review_vec = np.zeros(100)\n",
        "    count_words = 0\n",
        "    for word in review:\n",
        "        try:\n",
        "            vec = w2v_model.wv[word]\n",
        "            review_vec += vec\n",
        "            count_words += 1\n",
        "        except:\n",
        "            pass\n",
        "    review_vec /= count_words\n",
        "    review_vectors.append(review_vec)\n",
        "    \n",
        "review_vectors = np.array(review_vectors)\n",
        "review_vectors = np.nan_to_num(review_vectors)\n",
        "minPts = 2 * 100"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G11T2T75P1Ve"
      },
      "source": [
        "\n",
        "def lower_bound(nums, target): \n",
        "    l, r = 0, len(nums) - 1\n",
        "    while l <= r: \n",
        "        mid = int(l + (r - l) / 2)\n",
        "        if nums[mid] >= target:\n",
        "            r = mid - 1\n",
        "        else:\n",
        "            l = mid + 1\n",
        "    return l"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXDypn_YP1ZB"
      },
      "source": [
        "def compute_200th_nearest_neighbour(x, data): # Returns the distance of 200th nearest neighbour.\n",
        "    dists = []\n",
        "    for val in data:\n",
        "        dist = np.sum((x - val) **2 )\n",
        "        if(len(dists) == 200 and dists[199] > dist): \n",
        "            l = int(lower_bound(dists, dist))\n",
        "            if l < 200 and l >= 0 and dists[l] > dist:\n",
        "                dists[l] = dist\n",
        "        else:\n",
        "            dists.append(dist)\n",
        "            dists.sort()\n",
        "    \n",
        "    return dists[199]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "553As1FcP8gQ"
      },
      "source": [
        "\n",
        "two_hundreth_neighbour = []\n",
        "for val in review_vectors[:1500]:\n",
        "    two_hundreth_neighbour.append(compute_200th_nearest_neighbour(val, review_vectors[:1500]) )\n",
        "two_hundreth_neighbour.sort()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJyo1W6C5UPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8e26af-6715-4430-d1e3-bb87dfa2c058"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "optimal_epsilon = 8\n",
        "dbscan = DBSCAN(eps = optimal_epsilon, min_samples = 200).fit(review_vectors)\n",
        "mysample['DBSCAN Cluster Labels'] = dbscan.labels_\n",
        "print(mysample.groupby(['DBSCAN Cluster Labels'])['Reviews'].count())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DBSCAN Cluster Labels\n",
            "0    512\n",
            "Name: Reviews, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okCPEr5-5USm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eccaa4d1-fe89-48a3-bc54-1327494e6676"
      },
      "source": [
        "# HIERARCHICAL CLUSTERING\n",
        "agg_model = AgglomerativeClustering(n_clusters=6, affinity='euclidean', linkage='ward')\n",
        "Agg = agg_model.fit_predict(review_vectors)\n",
        "\n",
        "h_labels = agg_model.labels_\n",
        "h_silhouette_score = metrics.silhouette_score(review_vectors, h_labels, metric='euclidean')\n",
        "print('silhouette score:',h_silhouette_score)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "silhouette score: 0.5950469910833276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xBkc8PGwnCT"
      },
      "source": [
        "In one paragraph, please compare K means, DBSCAN and Hierarchical clustering. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwvPpJiNwnCT"
      },
      "source": [
        "\"\"\"\n",
        "from the above analysis:\n",
        "DBSCAN showed best performance followed by k-means clustering amd hierarchial clustering with 97% scoring and 60% respectively."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}